{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"nbformat\": 4,\n",
    "  \"nbformat_minor\": 2,\n",
    "  \"metadata\": {\n",
    "    \"colab\": {\n",
    "      \"name\": \"Introduction_to_Tensorflow.ipynb\",\n",
    "      \"provenance\": [],\n",
    "      \"collapsed_sections\": []\n",
    "    },\n",
    "    \"kernelspec\": {\n",
    "      \"name\": \"python3\",\n",
    "      \"display_name\": \"Python 3.7.9 64-bit ('venv': venv)\"\n",
    "    },\n",
    "    \"language_info\": {\n",
    "      \"name\": \"python\",\n",
    "      \"version\": \"3.7.9\",\n",
    "      \"mimetype\": \"text/x-python\",\n",
    "      \"codemirror_mode\": {\n",
    "        \"name\": \"ipython\",\n",
    "        \"version\": 3\n",
    "      },\n",
    "      \"pygments_lexer\": \"ipython3\",\n",
    "      \"nbconvert_exporter\": \"python\",\n",
    "      \"file_extension\": \".py\"\n",
    "    },\n",
    "    \"interpreter\": {\n",
    "      \"hash\": \"6ca9d643f7bb6934fb11056c6bfcbba6fffd6f45119b8d99fc29db1b9c71c5b0\"\n",
    "    },\n",
    "    \"accelerator\": \"GPU\"\n",
    "  },\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"# **NEUROENGINEERING AY 2021-22**\\n\",\n",
    "        \"## INTRODUCTION TO TENSORFLOW\\n\",\n",
    "        \"---\\n\",\n",
    "        \"### Matteo Rossi\\n\",\n",
    "        \"8 October 2021\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"PbPhwFNnoCGn\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"## **Introduction**\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"uZiSAoF_rZVt\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"In this notebook, we will try to teach a neural network to distinguish between paintings made by two painters with very different styles: Rembrandt (XVII century) and Pollock (XX century).\\n\",\n",
    "        \"\\n\",\n",
    "        \"We will use a custom made dataset, assembled by automatically scraping Google Images using *rembrandt painting* and *pollock painting* as search keys.\\n\",\n",
    "        \"Since this is only for demostration purposes, no control was done on the dataset, so some paintings could be of other artists, but still the two classes should be different enough to be distinguishable.\\n\",\n",
    "        \"\\n\",\n",
    "        \"The dataset is provided as a folder of images and a CSV (Comma Separated Values) file containing the labels for each image (0 for a Rembrandt, 1 for a Pollock).\\n\",\n",
    "        \"The dataset is available [here](https://drive.google.com/drive/folders/1PQd8lnioqx6cMMLXg42iv5cj7mzB6RZX?usp=sharing): as explained in the previous notebook, add it to your *My Drive* folder to make it accessible from Colab.\\n\",\n",
    "        \"\\n\",\n",
    "        \"The network we will build will be a simple convolutional neural network, made of the following layers:\\n\",\n",
    "        \"* 2D convolution\\n\",\n",
    "        \"  * 16 filters\\n\",\n",
    "        \"  * 3&times;3 kernel\\n\",\n",
    "        \"  * `same` padding\\n\",\n",
    "        \"  * hyperbolic tangent activation function\\n\",\n",
    "        \"* Max pooling\\n\",\n",
    "        \"    * 2&times;2 pool size\\n\",\n",
    "        \"* Rectified Linear Unit ([`keras.layers.ReLU`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU))\\n\",\n",
    "        \"* Repeat 2D convolution + Max pooling + ReLU\\n\",\n",
    "        \"* Fully connected\\n\",\n",
    "        \"  * 128 units\\n\",\n",
    "        \"  * hyperbolic tangent activation function\\n\",\n",
    "        \"* Output layer\\n\",\n",
    "        \"  * ? units\\n\",\n",
    "        \"  * ? activation function\\n\",\n",
    "        \"\\n\",\n",
    "        \"The network will receive as input 100&times;100 pixels RGB images.\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"G3uRMy-ooQok\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"## **Set up the environment**\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"RmJwm0OCv1hM\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"First of all, you need to access the [dataset folder](https://drive.google.com/drive/folders/1PQd8lnioqx6cMMLXg42iv5cj7mzB6RZX?usp=sharing) and add it to *My Drive*.\\n\",\n",
    "        \"Once you have done that, you can mount the *My Drive* folder to make it accessible in Colab.\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"0TATFIYav4GY\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"from google.colab import drive\\r\\n\",\n",
    "        \"drive.mount('/content/drive')\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"ODtwKDSYwNn9\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"outputId\": \"ebc9c74b-9484-4b4a-cfef-8968e99b94b1\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"If you did everything correctly, the dataset should be available at the following path:\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"4YjUN0TcxFC3\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"NEUROART_FOLDER = \\\"/content/drive/My Drive/workshop_neuroengineering/neuroart\\\"\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"N6EUH-QZhh_O\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"Check that the folder was correctly loaded by listing its content.\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"7fkOkqfWxWKU\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"import os\\r\\n\",\n",
    "        \"os.listdir(NEUROART_FOLDER)\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"GxnK3c7xwRDi\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"outputId\": \"42992b29-1aff-48a6-a046-08718dc5af8e\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"*Note: [`os.path.join`](https://docs.python.org/3/library/os.path.html#os.path.join) is used to combine multiple relative paths in a single one*\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"1qKFAo2IyHmI\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"LABELS_FILE   = os.path.join(NEUROART_FOLDER, 'labels.csv')\\r\\n\",\n",
    "        \"IMAGES_FOLDER = os.path.join(NEUROART_FOLDER, 'images')\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"RmDJ_z8-yKZB\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"Now we are ready to load the dataset, create the neural network and train it.\\n\",\n",
    "        \"Below are the modules we will need:\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"LP1QhgKi1BbF\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"import tensorflow as tf         \\r\\n\",\n",
    "        \"import numpy as np              # useful for managin multidimensional arrays\\r\\n\",\n",
    "        \"import matplotlib.pyplot as plt # to display images and plots\\r\\n\",\n",
    "        \"from PIL import Image           # to read, write and manipulate images\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"5gbUYe4IsnqS\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"And here some definitions we will need later on:\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Z2TA2Jto2Im6\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"LABELS = ['Rembrandt', 'Pollock'] # 0 = Rembrandt, 1 = Pollock\\r\\n\",\n",
    "        \"IMAGE_WIDTH  = 100\\r\\n\",\n",
    "        \"IMAGE_HEIGHT = 100\\r\\n\",\n",
    "        \"IMAGE_DEPTH  = 3 # RGB image\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"eEMKmNk8huh4\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"## **Load dataset**\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"vYfnNtZN2Suw\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"It is now time to load the data from the dataset and convert it to a format that is suitable for Keras (i.e. a [`numpy.ndarray`](https://docs.scipy.org/doc/numpy-1.17.0/reference/generated/numpy.ndarray.html#numpy.ndarray) of images as input and a [`numpy.ndarray`](https://docs.scipy.org/doc/numpy-1.17.0/reference/generated/numpy.ndarray.html#numpy.ndarray) of labels as output).\\n\",\n",
    "        \"\\n\",\n",
    "        \"The following code reads the content of the file containing the labels:\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Etwaczz62Vg-\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"csvfile = open(LABELS_FILE, 'r')\\r\\n\",\n",
    "        \"content = csvfile.read()\\r\\n\",\n",
    "        \"csvfile.close()\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"acdAUNsl3Ewf\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"The string method [`split`](https://docs.python.org/3/library/stdtypes.html#str.split) allows us to divide a string in pieces based on a separator.\\n\",\n",
    "        \"In particular, we can use `.split('\\\\n')` to split based on the newline separator, hence obtaining a list of file lines.\\n\",\n",
    "        \"\\n\",\n",
    "        \"Using it, try to print out the first 10 lines of the file to better understand its structure.\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"OZWzbcma3HBm\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"# Print first 10 lines of the CSV file [solution]\\r\\n\",\n",
    "        \"lines = content.split(\\\"\\\\n\\\")\\r\\n\",\n",
    "        \"for line in lines[:10]:\\r\\n\",\n",
    "        \"    print(line)\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"ko7j-AB24gGv\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"outputId\": \"f9451027-2ec1-4cd3-f4c3-d52bda12b4e4\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"As you can see, each line contains two values separated by a comma.\\n\",\n",
    "        \"The first one is the path of an image and the second one is the label associated to it (either `0` or `1`).\\n\",\n",
    "        \"\\n\",\n",
    "        \"Using the [`split`](https://docs.python.org/3/library/stdtypes.html#str.split) method again, we can now completely convert the CSV file into a table:\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"SWGUhdEi45R8\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"table = []\\r\\n\",\n",
    "        \"for line in content.split(\\\"\\\\n\\\"):\\r\\n\",\n",
    "        \"    if line == \\\"\\\": # Skip empty lines\\r\\n\",\n",
    "        \"        continue\\r\\n\",\n",
    "        \"    path, label = line.split(\\\",\\\")\\r\\n\",\n",
    "        \"    table.append([path, label])\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"print(table)\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"qEhtiNji6BSQ\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"outputId\": \"3f000b11-c7f6-4442-ae39-8127ab80b3bd\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"We can now check if the two classes are balanced by counting the images in each class, displaying a bar plot of the distribution and printing the count.\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Q9oVHNlaB0kP\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"# Check class balance\\r\\n\",\n",
    "        \"rembrandt_count = 0\\r\\n\",\n",
    "        \"pollock_count   = 0\\r\\n\",\n",
    "        \"for row in table:\\r\\n\",\n",
    "        \"    path, label = row\\r\\n\",\n",
    "        \"    if label == \\\"0\\\":\\r\\n\",\n",
    "        \"        rembrandt_count += 1\\r\\n\",\n",
    "        \"    else:\\r\\n\",\n",
    "        \"        pollock_count += 1\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"plt.bar([0,1], [rembrandt_count, pollock_count])\\r\\n\",\n",
    "        \"plt.xticks([0,1], labels=LABELS)\\r\\n\",\n",
    "        \"print(\\\"Rembrandt: {} images\\\".format(rembrandt_count))\\r\\n\",\n",
    "        \"print(\\\"Pollock: {} images\\\".format(pollock_count))\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Gf8E_44aCCS5\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\",\n",
    "          \"height\": 298\n",
    "        },\n",
    "        \"outputId\": \"76cb5a2c-1cba-49c5-bbcc-45e0727e9c74\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"For a correct evaluation of our network, we should not use the whole dataset for training and instead keep a part of it for validation.\\n\",\n",
    "        \"As an example, we will split the data in this way:\\n\",\n",
    "        \"* **80%** of the images in the training set\\n\",\n",
    "        \"* **20%** of the images in the validation set\\n\",\n",
    "        \"\\n\",\n",
    "        \"We need to find the number of examples in the training and validation set.\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"wN1vydtV6l5u\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"# Compute size of training and validation set\\r\\n\",\n",
    "        \"TOTAL_EXAMPLES      = len(table)\\r\\n\",\n",
    "        \"TRAINING_EXAMPLES   = int(0.8*TOTAL_EXAMPLES)\\r\\n\",\n",
    "        \"VALIDATION_EXAMPLES = TOTAL_EXAMPLES - TRAINING_EXAMPLES\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"print(TOTAL_EXAMPLES)\\r\\n\",\n",
    "        \"print(TRAINING_EXAMPLES)\\r\\n\",\n",
    "        \"print(VALIDATION_EXAMPLES)\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"yFvRByD29vDl\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"outputId\": \"0212e232-69c8-4768-ad20-3ef8e966e4b7\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"We could just split the whole table at 80% of its length and assign each part to the training and validation set, but there is a risk of having unbalanced classes in the two sets.\\n\",\n",
    "        \"It is better to first assign the images to two different groups (one for each class) and then divide each group in the training and validation set.\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"R8SOVIlk_RJZ\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"# Divide table based on label\\r\\n\",\n",
    "        \"rembrandt_examples = []\\r\\n\",\n",
    "        \"pollock_examples = []\\r\\n\",\n",
    "        \"for row in table:\\r\\n\",\n",
    "        \"    path, label = row\\r\\n\",\n",
    "        \"    if label == \\\"0\\\":\\r\\n\",\n",
    "        \"        rembrandt_examples.append(path)\\r\\n\",\n",
    "        \"    else:\\r\\n\",\n",
    "        \"        pollock_examples.append(path)\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"toAHiqggBHe9\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"Since the two classes have balanced, we can get the number of examples for each label as half the total number of examples in a set:\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"uVEddbVrBsDs\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"# two slashes are used for integer division\\r\\n\",\n",
    "        \"TRAINING_REMBRANDT_EXAMPLES = TRAINING_EXAMPLES//2\\r\\n\",\n",
    "        \"TRAINING_POLLOCK_EXAMPLES = TRAINING_EXAMPLES - TRAINING_REMBRANDT_EXAMPLES\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"VALIDATION_POLLOCK_EXAMPLES = VALIDATION_EXAMPLES//2\\r\\n\",\n",
    "        \"VALIDATION_REMBRANDT_EXAMPLES = VALIDATION_EXAMPLES - VALIDATION_POLLOCK_EXAMPLES\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"print(f\\\"Training Rembrandt examples: {TRAINING_REMBRANDT_EXAMPLES}\\\")\\r\\n\",\n",
    "        \"print(f\\\"Validation Rembrandt examples: {VALIDATION_REMBRANDT_EXAMPLES}\\\")\\r\\n\",\n",
    "        \"print(f\\\"Training Pollock examples: {TRAINING_POLLOCK_EXAMPLES}\\\")\\r\\n\",\n",
    "        \"print(f\\\"Validation Pollock examples: {VALIDATION_POLLOCK_EXAMPLES}\\\")\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"NtGnP7A3Bf4X\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"outputId\": \"1f760308-b043-4a61-afc2-b0f63ecda2f7\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"We can now actually create the training and validation set in a form that is suitable for Keras.\\n\",\n",
    "        \"Since this part is a little more complex, the code is provided for the Rembrandt class in the training set.\\n\",\n",
    "        \"\\n\",\n",
    "        \"Some information about the code:\\n\",\n",
    "        \"* [`numpy.empty`](https://docs.scipy.org/doc/numpy-1.17.0/reference/generated/numpy.empty.html#numpy.empty) creates a multidimensional array (which shape must be specified without initializing its content\\n\",\n",
    "        \"* [`enumerate`](https://docs.python.org/3/library/functions.html#enumerate) takes a list and converts it to a list of pairs `(index, list_element)`; it is useful to iterate through a list while keeping track of the iteration number\\n\",\n",
    "        \"* [`Image.open`](https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.open) creates a [`PIL.Image`](https://pillow.readthedocs.io/en/stable/reference/Image.html) object from a given path; this object has some useful methods:\\n\",\n",
    "        \"  * [`.convert`](https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.convert) allows to set the color mode of the image (e.g. grayscale `L`, true color `RGB`, true color with transparency mask `RGBA`)\\n\",\n",
    "        \"  * [`.resize`](https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.resize) allows to shrink or expand an image to a specific size\\n\",\n",
    "        \"* [`numpy.asarray`](https://docs.scipy.org/doc/numpy-1.17.0/reference/generated/numpy.asarray.html#numpy.asarray) converts (among other things) [`PIL.Image`](https://pillow.readthedocs.io/en/stable/reference/Image.html) objects to [`numpy.ndarray`](https://docs.scipy.org/doc/numpy-1.17.0/reference/generated/numpy.ndarray.html#numpy.ndarray) objects\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"1BVL18ThFAoM\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"# Initialize arrays\\r\\n\",\n",
    "        \"train_images = np.empty((TRAINING_EXAMPLES, IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_DEPTH))\\r\\n\",\n",
    "        \"valid_images = np.empty((VALIDATION_EXAMPLES, IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_DEPTH))\\r\\n\",\n",
    "        \"train_labels = np.empty(TRAINING_EXAMPLES)\\r\\n\",\n",
    "        \"valid_labels = np.empty(VALIDATION_EXAMPLES)\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"8pS_zxYnxeqS\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"Now let's fill the array for every case.\\n\",\n",
    "        \"\\n\",\n",
    "        \"*Hint: [`enumerate`](https://docs.python.org/3/library/functions.html#enumerate) accepts an optional second paramenter `start` that indicates which should be the starting value of the iteration counter*\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"KEpognKDIcyl\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"### Load training images\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"NfMv6R5xIz2q\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"# Load training set - Rembrandt class\\r\\n\",\n",
    "        \"for i, path in enumerate(rembrandt_examples[:TRAINING_REMBRANDT_EXAMPLES]):\\r\\n\",\n",
    "        \"    print(\\r\\n\",\n",
    "        \"        \\\"\\\\rTraining Rembrandt - Loaded: {}/{}\\\"\\r\\n\",\n",
    "        \"            .format(i+1, TRAINING_REMBRANDT_EXAMPLES),\\r\\n\",\n",
    "        \"        end=\\\"\\\"\\r\\n\",\n",
    "        \"    )\\r\\n\",\n",
    "        \"    #print(os.path.join(IMAGES_FOLDER, path))\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"    image = Image.open(os.path.join(IMAGES_FOLDER, path)).convert(\\\"RGB\\\")\\r\\n\",\n",
    "        \"    image = image.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\\r\\n\",\n",
    "        \"    train_images[i] = np.asarray(image)\\r\\n\",\n",
    "        \"    train_labels[i] = 0\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"id\": \"EM5zK8udIz2r\",\n",
    "        \"outputId\": \"8ca52581-ae7e-409f-dceb-82b0667676d4\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"# Load training set - Pollock class\\r\\n\",\n",
    "        \"for i, path in enumerate(pollock_examples[:TRAINING_POLLOCK_EXAMPLES], start=TRAINING_REMBRANDT_EXAMPLES):\\r\\n\",\n",
    "        \"    print(\\r\\n\",\n",
    "        \"        \\\"\\\\rTraining Pollock - Loaded: {}/{}\\\"\\r\\n\",\n",
    "        \"            .format(i+1, TRAINING_EXAMPLES),\\r\\n\",\n",
    "        \"        end=\\\"\\\"\\r\\n\",\n",
    "        \"    )\\r\\n\",\n",
    "        \"    #print(os.path.join(IMAGES_FOLDER, path))\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"    image = Image.open(os.path.join(IMAGES_FOLDER, path)).convert(\\\"RGB\\\")\\r\\n\",\n",
    "        \"    image = image.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\\r\\n\",\n",
    "        \"    train_images[i] = np.asarray(image)\\r\\n\",\n",
    "        \"    train_labels[i] = 1\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"id\": \"4yY1XgsAIz2r\",\n",
    "        \"outputId\": \"a8e6d047-78f5-47ae-daba-6bfe528308b2\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"### Load Validation images\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"chCXPtsaIz2r\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"# Load validation set - Rembrandt class\\r\\n\",\n",
    "        \"for i, path in enumerate(rembrandt_examples[TRAINING_REMBRANDT_EXAMPLES:]):\\r\\n\",\n",
    "        \"    print(\\r\\n\",\n",
    "        \"        \\\"\\\\rValidation Rembrandt - Loaded: {}/{}\\\"\\r\\n\",\n",
    "        \"            .format(i+1, VALIDATION_REMBRANDT_EXAMPLES),\\r\\n\",\n",
    "        \"        end=\\\"\\\"\\r\\n\",\n",
    "        \"    )\\r\\n\",\n",
    "        \"    #print(os.path.join(IMAGES_FOLDER, path))\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"    image = Image.open(os.path.join(IMAGES_FOLDER, path)).convert(\\\"RGB\\\")\\r\\n\",\n",
    "        \"    image = image.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\\r\\n\",\n",
    "        \"    valid_images[i] = np.asarray(image)\\r\\n\",\n",
    "        \"    valid_labels[i] = 0\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"EeTT5NnnIiyk\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"outputId\": \"18a05707-4177-45b0-c9f0-e1406fc2d2dc\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"# Load validation set - Pollock class\\r\\n\",\n",
    "        \"for i, path in enumerate(pollock_examples[TRAINING_POLLOCK_EXAMPLES:], start=VALIDATION_REMBRANDT_EXAMPLES):\\r\\n\",\n",
    "        \"    print(\\r\\n\",\n",
    "        \"        \\\"\\\\rValidation Pollock - Loaded: {}/{}\\\"\\r\\n\",\n",
    "        \"            .format(i+1, VALIDATION_EXAMPLES),\\r\\n\",\n",
    "        \"        end=\\\"\\\"\\r\\n\",\n",
    "        \"    )\\r\\n\",\n",
    "        \"    #print(os.path.join(IMAGES_FOLDER, path))\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"    image = Image.open(os.path.join(IMAGES_FOLDER, path)).convert(\\\"RGB\\\")\\r\\n\",\n",
    "        \"    image = image.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\\r\\n\",\n",
    "        \"    valid_images[i] = np.asarray(image)\\r\\n\",\n",
    "        \"    valid_labels[i] = 1\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"id\": \"yhc42ujgIz2s\",\n",
    "        \"outputId\": \"c76a6e29-2de0-429d-f0c1-f6ba90453788\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"To see if the data was loaded correctly, we can display some images from the training and test set (say 5 and 5) with their respective labels in a grid.\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"qpv8ivQrOLO0\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"# Display examples from the datasets\\r\\n\",\n",
    "        \"plt.figure(figsize=(20,8))\\r\\n\",\n",
    "        \"for i in range(5):\\r\\n\",\n",
    "        \"    plt.subplot(2,5,i+1)\\r\\n\",\n",
    "        \"    image = train_images[i].astype(np.uint8)\\r\\n\",\n",
    "        \"    plt.imshow(image)\\r\\n\",\n",
    "        \"    plt.xlabel(LABELS[train_labels.astype(int)[i]])\\r\\n\",\n",
    "        \"    plt.xticks([])\\r\\n\",\n",
    "        \"    plt.yticks([])\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"    plt.subplot(2,5,i+6)\\r\\n\",\n",
    "        \"    image = valid_images[i].astype(np.uint8)\\r\\n\",\n",
    "        \"    plt.imshow(image)\\r\\n\",\n",
    "        \"    plt.xlabel(LABELS[valid_labels.astype(int)[i]])\\r\\n\",\n",
    "        \"    plt.xticks([])\\r\\n\",\n",
    "        \"    plt.yticks([])\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"QAd3GTvzx_tC\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\",\n",
    "          \"height\": 455\n",
    "        },\n",
    "        \"outputId\": \"9a8ef00c-879d-40a0-be86-a7e483bee615\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"Since we loaded all Rembrandt paintings first and then the Pollock paintings, we only display the Rembrandt ones here.\\n\",\n",
    "        \"It is good practice to randomize the order of the examples before feeding the to the neural network.\\n\",\n",
    "        \"\\n\",\n",
    "        \"The [`numpy.random.shuffle`](https://docs.scipy.org/doc/numpy-1.17.0/reference/random/generated/numpy.random.mtrand.RandomState.shuffle.html#numpy.random.mtrand.RandomState.shuffle) function randomizes the order of a list-like object in-place. In cases like this where we want to shuffle two lists at the same time (we want to keep the link between images and labels) it is better to use [`numpy.random.permutation`](https://docs.scipy.org/doc/numpy-1.17.0/reference/random/generated/numpy.random.mtrand.RandomState.permutation.html#numpy.random.mtrand.RandomState.permutation):\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"mmhcmOzpNgaE\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"new_order = np.random.permutation(TRAINING_EXAMPLES)\\r\\n\",\n",
    "        \"train_images = train_images[new_order]\\r\\n\",\n",
    "        \"train_labels = train_labels[new_order]\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"new_order = np.random.permutation(VALIDATION_EXAMPLES)\\r\\n\",\n",
    "        \"valid_images = valid_images[new_order]\\r\\n\",\n",
    "        \"valid_labels = valid_labels[new_order]\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"X05SSdZ7NlSf\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"If we display the images again, they will be mixed up.\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"q9NcB91TQrLC\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"plt.figure(figsize=(20,8))\\r\\n\",\n",
    "        \"for i in range(5):\\r\\n\",\n",
    "        \"    plt.subplot(2,5,i+1)\\r\\n\",\n",
    "        \"    image = train_images[i].astype(np.uint8)\\r\\n\",\n",
    "        \"    plt.imshow(image)\\r\\n\",\n",
    "        \"    plt.xlabel(LABELS[train_labels.astype(int)[i]])\\r\\n\",\n",
    "        \"    plt.xticks([])\\r\\n\",\n",
    "        \"    plt.yticks([])\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"    plt.subplot(2,5,i+6)\\r\\n\",\n",
    "        \"    image = valid_images[i].astype(np.uint8)\\r\\n\",\n",
    "        \"    plt.imshow(image)\\r\\n\",\n",
    "        \"    plt.xlabel(LABELS[valid_labels.astype(int)[i]])\\r\\n\",\n",
    "        \"    plt.xticks([])\\r\\n\",\n",
    "        \"    plt.yticks([])\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"duGO8IUHQu-s\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\",\n",
    "          \"height\": 455\n",
    "        },\n",
    "        \"outputId\": \"ba779fc2-dc73-4b11-dfa8-904ca28630f9\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"## **Build model**\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"x-NJT7UWP_Xl\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"At this point we can create the actual neural network.\\n\",\n",
    "        \"Remember that we want a simple convolutional neural network with the following layers:\\n\",\n",
    "        \"* 2D convolution\\n\",\n",
    "        \"  * 16 filters\\n\",\n",
    "        \"  * 3&times;3 kernel\\n\",\n",
    "        \"  * `same` padding\\n\",\n",
    "        \"  * hyperbolic tangent activation function\\n\",\n",
    "        \"* Max pooling\\n\",\n",
    "        \"    * 2&times;2 pool size\\n\",\n",
    "        \"* Rectified Linear Unit ([`keras.layers.ReLU`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU))\\n\",\n",
    "        \"* Repeat 2D convolution + Max pooling + ReLU\\n\",\n",
    "        \"* Fully connected\\n\",\n",
    "        \"  * 128 units\\n\",\n",
    "        \"  * hyperbolic tangent activation function\\n\",\n",
    "        \"* Output layer\\n\",\n",
    "        \"  * ? units\\n\",\n",
    "        \"  * ? activation function\\n\",\n",
    "        \"\\n\",\n",
    "        \"How many outputs should the network have and which activation function is most suitable?\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"UEZ5f3P8QITm\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"# Build the model [solution]\\r\\n\",\n",
    "        \"def build_model(image_width, image_height, image_depth):\\r\\n\",\n",
    "        \"    input_layer = tf.keras.layers.Input(shape=[image_width, image_height, image_depth])\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"    layers = tf.keras.layers.Conv2D(filters=16,\\r\\n\",\n",
    "        \"                                kernel_size=(3,3),\\r\\n\",\n",
    "        \"                                padding=\\\"same\\\",\\r\\n\",\n",
    "        \"                                activation=\\\"tanh\\\")(input_layer)\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"    layers = tf.keras.layers.MaxPool2D(pool_size=(2,2))(layers)\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"    layers = tf.keras.layers.ReLU()(layers)\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"    layers = tf.keras.layers.Conv2D(filters=16,\\r\\n\",\n",
    "        \"                                kernel_size=(3,3),\\r\\n\",\n",
    "        \"                                padding=\\\"same\\\",\\r\\n\",\n",
    "        \"                                activation=\\\"tanh\\\")(layers)\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"    layers = tf.keras.layers.MaxPool2D(pool_size=(2,2))(layers)\\r\\n\",\n",
    "        \"    layers = tf.keras.layers.ReLU()(layers)\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"    layers = tf.keras.layers.Flatten()(layers)\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"    layers = tf.keras.layers.Dense(128, activation=\\\"tanh\\\")(layers)\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"    output_layer = tf.keras.layers.Dense(1, activation=\\\"sigmoid\\\")(layers)\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"    model = tf.keras.Model(inputs=input_layer,\\r\\n\",\n",
    "        \"                        outputs=output_layer,\\r\\n\",\n",
    "        \"                        name=\\\"neuroart_model\\\"\\r\\n\",\n",
    "        \"                        )\\r\\n\",\n",
    "        \"    \\r\\n\",\n",
    "        \"    return model\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"# Build a new model\\r\\n\",\n",
    "        \"model = build_model(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_DEPTH)\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"8mzyNZExnVUx\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"model.summary()\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"OLJd98cFpv1e\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"outputId\": \"997fbe19-cd02-4404-9fd3-48e086d1200e\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"tf.keras.utils.plot_model(model, show_shapes=True)\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"DkQV0glYpxTi\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\",\n",
    "          \"height\": 1000\n",
    "        },\n",
    "        \"outputId\": \"8549160e-6149-4735-ae0d-ff3c8242ffbb\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"## **Compile the model**\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"6cXt-7joRFQs\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"Always remember to compile the model before training it.\\n\",\n",
    "        \"Since we are performing a binary classification, we use the `binary_crossentropy` loss function.\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"SGSjK_xwRHuf\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"model.compile(\\r\\n\",\n",
    "        \"    optimizer = tf.keras.optimizers.Adam(),\\r\\n\",\n",
    "        \"    loss = 'binary_crossentropy',\\r\\n\",\n",
    "        \"    metrics = ['acc']\\r\\n\",\n",
    "        \")\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"7CDRR032RKw3\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"## **Train the model**\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"jsPpI0oJRUnG\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"Use the [`.fit`](https://keras.io/models/model/#fit) method of the model to train it.\\n\",\n",
    "        \"\\n\",\n",
    "        \"In addition to the training data, you can pass a pair of `(images, labels)` as the `validation_data` argument to the [`.fit`](https://keras.io/models/model/#fit) method in order to monitor the loss function and accuracy on validation data that is not used for training and this way detect if overfitting is occurring.\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"-7HYE-xMReCP\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"# Train the model [solution]\\r\\n\",\n",
    "        \"history = model.fit(train_images, \\r\\n\",\n",
    "        \"                    train_labels, \\r\\n\",\n",
    "        \"                    batch_size=256, \\r\\n\",\n",
    "        \"                    epochs=30, \\r\\n\",\n",
    "        \"                    validation_data=(valid_images, valid_labels))\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"8lO66pqijkS6\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"outputId\": \"d06611b3-fd5c-49fd-e438-f802dbc9a420\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"The `history` variable that we saved stores how the network evolved during training.\\n\",\n",
    "        \"\\n\",\n",
    "        \"We can, for example, see how the loss changed epoch by epoch:\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"j1VVufliTIDQ\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"plt.plot(history.history['loss'], label=\\\"training loss\\\")\\r\\n\",\n",
    "        \"plt.plot(history.history['val_loss'], label=\\\"validation loss\\\")\\r\\n\",\n",
    "        \"plt.legend()\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"6rse7MTFkY3I\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\",\n",
    "          \"height\": 282\n",
    "        },\n",
    "        \"outputId\": \"bd074f01-ad5f-4214-abc9-2098ee7918d6\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"Do the same for the accuracy.\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"fZZaIZpFTa6o\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"# Plot accuracy epoch by epoch\\r\\n\",\n",
    "        \"plt.plot(history.history['acc'], label=\\\"training accuracy\\\")\\r\\n\",\n",
    "        \"plt.plot(history.history['val_acc'], label=\\\"validation accuracy\\\")\\r\\n\",\n",
    "        \"plt.legend()\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"kDnTND8rt4p0\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\",\n",
    "          \"height\": 282\n",
    "        },\n",
    "        \"outputId\": \"adbc4ab7-48de-45c1-b584-f76f45a94540\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"## **Make predictions**\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Dc4X-88xUHEp\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"Now that we have a working network, we can try to predict the label of some image.\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"4QQUB0aAUNMb\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"images = np.concatenate([train_images[:5], valid_images[:5]])\\r\\n\",\n",
    "        \"labels = np.concatenate([train_labels[:5], valid_labels[:5]])\\r\\n\",\n",
    "        \"predictions = model.predict(images)\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"UUIayYDQWBYZ\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"And now we can show it.\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"ULgq-xINWR96\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"plt.figure(figsize=(20,8))\\r\\n\",\n",
    "        \"for i in range(10):\\r\\n\",\n",
    "        \"    plt.subplot(2,5,i+1)\\r\\n\",\n",
    "        \"    image = images[i].astype(np.uint8)\\r\\n\",\n",
    "        \"    true  = int(labels[i])\\r\\n\",\n",
    "        \"    pred  = int(np.round(predictions[i])) # Take closest integer\\r\\n\",\n",
    "        \"    plt.imshow(image)\\r\\n\",\n",
    "        \"    plt.xlabel(\\r\\n\",\n",
    "        \"        \\\"True {}\\\\nPred. {}\\\".format(\\r\\n\",\n",
    "        \"            LABELS[true],\\r\\n\",\n",
    "        \"            LABELS[pred]\\r\\n\",\n",
    "        \"        )\\r\\n\",\n",
    "        \"    )\\r\\n\",\n",
    "        \"    plt.xticks([])\\r\\n\",\n",
    "        \"    plt.yticks([])\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"2ya5VhSYWLN4\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\",\n",
    "          \"height\": 466\n",
    "        },\n",
    "        \"outputId\": \"f4d5396d-f84e-4fba-b49e-54c33e8cfef2\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"## **Advanced settings**\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"KNfuN9-IjSyo\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"\\n\",\n",
    "        \"In this section we will see how to:\\n\",\n",
    "        \"- use Tensorboard\\n\",\n",
    "        \"- save model checkpoints\\n\",\n",
    "        \"- restore a model previously saved\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"xzhnUBzt4mbh\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"from datetime import datetime\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"vpFEnWjUG9cO\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"### Tensorboard\\n\",\n",
    "        \"This is a very useful tool to keep track of your loss and metrics at runtime. With respect to the history variable you don't need to wait the end of the training. \\n\",\n",
    "        \"\\n\",\n",
    "        \"For a detailed explanation of Tensorboard see this [link](https://www.tensorflow.org/tensorboard/get_started)\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"cz1CNDPz9-e5\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"TB_FOLDER =  os.path.join(NEUROART_FOLDER, 'tensorboard_logs')\\r\\n\",\n",
    "        \"try:\\r\\n\",\n",
    "        \"    os.mkdir(TB_FOLDER)\\r\\n\",\n",
    "        \"except:\\r\\n\",\n",
    "        \"    pass\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"-LzMt7OV-Ifb\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"logdir = os.path.join(TB_FOLDER, datetime.now().strftime(\\\"%Y%m%d-%H%M%S\\\"))\\r\\n\",\n",
    "        \"tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"JnL5JayF-UmL\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"# run and copy the output\\r\\n\",\n",
    "        \"TB_FOLDER\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"dfy-4iz6_Ha4\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\",\n",
    "          \"height\": 35\n",
    "        },\n",
    "        \"outputId\": \"0b72e2a5-775f-43ac-db0f-67656b8db0f2\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"# Load the TensorBoard notebook extension\\r\\n\",\n",
    "        \"%load_ext tensorboard\\r\\n\",\n",
    "        \"%tensorboard --logdir '/content/drive/My Drive/workshop_neuroengineering/neuroart/tensorboard_logs' # paste here the output of the previews cell\\r\\n\",\n",
    "        \"# !!!!!! pay attention to have your path between quotation marks 'path/to/logs_folder'\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"nvGQ6K-s-djl\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"# Build a new model\\r\\n\",\n",
    "        \"modelA = build_model(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_DEPTH)\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Nli_yefnd4eK\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"modelA.compile(\\r\\n\",\n",
    "        \"    optimizer = tf.keras.optimizers.Adam(),\\r\\n\",\n",
    "        \"    loss = 'binary_crossentropy',\\r\\n\",\n",
    "        \"    metrics = ['acc']\\r\\n\",\n",
    "        \")\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"XUmPYNns-kdS\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"historyA = modelA.fit(train_images, \\r\\n\",\n",
    "        \"                    train_labels, \\r\\n\",\n",
    "        \"                    batch_size=256, \\r\\n\",\n",
    "        \"                    epochs=100,\\r\\n\",\n",
    "        \"                    validation_data=(valid_images, valid_labels),\\r\\n\",\n",
    "        \"                    callbacks=[tensorboard_callback])\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"_b8FJAkB-s3i\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"outputId\": \"3100d7d1-b833-420c-fe84-d1a4a9592a55\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"### Model checkpoint\\n\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"8tmRGL2V-97q\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"CKPT_FOLDER =  os.path.join(NEUROART_FOLDER, 'model_checkpoints')\\r\\n\",\n",
    "        \"try:\\r\\n\",\n",
    "        \"    os.mkdir(CKPT_FOLDER)\\r\\n\",\n",
    "        \"except:\\r\\n\",\n",
    "        \"    pass\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"wKxEzPVrL1NW\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"# Build a new model\\r\\n\",\n",
    "        \"modelB = build_model(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_DEPTH)\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"CIGE5ajEgE6H\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"modelB.compile(\\r\\n\",\n",
    "        \"    optimizer = tf.keras.optimizers.Adam(),\\r\\n\",\n",
    "        \"    loss = 'binary_crossentropy',\\r\\n\",\n",
    "        \"    metrics = ['acc']\\r\\n\",\n",
    "        \")\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"Pgyu5Ung_V1X\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"checkpointer_val_loss = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(CKPT_FOLDER,\\r\\n\",\n",
    "        \"                                                                                 \\\"best_min_val_loss.h5\\\"), \\r\\n\",\n",
    "        \"                                                           monitor='val_loss',\\r\\n\",\n",
    "        \"                                                           verbose=1,\\r\\n\",\n",
    "        \"                                                           save_best_only=True,\\r\\n\",\n",
    "        \"                                                           mode='min',         \\r\\n\",\n",
    "        \"                                                           save_freq=\\\"epoch\\\")\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"checkpointer_val_acc = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(CKPT_FOLDER,\\r\\n\",\n",
    "        \"                                                                                \\\"best_max_val_acc.h5\\\"),\\r\\n\",\n",
    "        \"                                                          monitor='val_acc',\\r\\n\",\n",
    "        \"                                                          verbose=1,\\r\\n\",\n",
    "        \"                                                          save_best_only=True,\\r\\n\",\n",
    "        \"                                                          mode='max',\\r\\n\",\n",
    "        \"                                                          save_freq=\\\"epoch\\\")\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"pKYUkRZ0_Dra\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"historyB = modelB.fit(train_images,\\r\\n\",\n",
    "        \"                      train_labels,\\r\\n\",\n",
    "        \"                      batch_size=256,\\r\\n\",\n",
    "        \"                      epochs=50,\\r\\n\",\n",
    "        \"                      validation_data=(valid_images, valid_labels),\\r\\n\",\n",
    "        \"                      callbacks=[\\r\\n\",\n",
    "        \"                                 checkpointer_val_loss,\\r\\n\",\n",
    "        \"                                 checkpointer_val_acc\\r\\n\",\n",
    "        \"                                 ]\\r\\n\",\n",
    "        \"                    )\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"YgiRyT90_Kzl\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"outputId\": \"faa66e9d-82e4-4f68-cea6-30c87acda46b\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"source\": [\n",
    "        \"### Restore a previously saved model\\n\",\n",
    "        \"It can be used to rebuild the same model in a second moment.\"\n",
    "      ],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"bbL-EnocGdBf\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"# Load the model that reached the highest accuracy\\r\\n\",\n",
    "        \"modelPath = os.path.join(CKPT_FOLDER, \\\"best_max_val_acc.h5\\\")\\r\\n\",\n",
    "        \"print(modelPath)\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"# if you want just to make prediction\\r\\n\",\n",
    "        \"reconstructed_model = tf.keras.models.load_model(modelPath, compile=False)\\r\\n\",\n",
    "        \"\\r\\n\",\n",
    "        \"#reconstructed_model = build_model(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_DEPTH)\\r\\n\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"nsoMpKXZGjCV\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\"\n",
    "        },\n",
    "        \"outputId\": \"07458124-ae62-4143-ddf8-8bef66e3d4a7\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"predictions = reconstructed_model.predict(images)\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"op5o1Fg8IZlB\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"source\": [\n",
    "        \"plt.figure(figsize=(20,8))\\r\\n\",\n",
    "        \"for i in range(10):\\r\\n\",\n",
    "        \"    plt.subplot(2,5,i+1)\\r\\n\",\n",
    "        \"    image = images[i].astype(np.uint8)\\r\\n\",\n",
    "        \"    true  = int(labels[i])\\r\\n\",\n",
    "        \"    pred  = int(np.round(predictions[i])) # Take closest integer\\r\\n\",\n",
    "        \"    plt.imshow(image)\\r\\n\",\n",
    "        \"    plt.xlabel(\\r\\n\",\n",
    "        \"        \\\"True {}\\\\nPred. {}\\\".format(\\r\\n\",\n",
    "        \"            LABELS[true],\\r\\n\",\n",
    "        \"            LABELS[pred]\\r\\n\",\n",
    "        \"        )\\r\\n\",\n",
    "        \"    )\\r\\n\",\n",
    "        \"    plt.xticks([])\\r\\n\",\n",
    "        \"    plt.yticks([])\"\n",
    "      ],\n",
    "      \"outputs\": [],\n",
    "      \"metadata\": {\n",
    "        \"id\": \"WbSLOq2iIkWG\",\n",
    "        \"colab\": {\n",
    "          \"base_uri\": \"https://localhost:8080/\",\n",
    "          \"height\": 466\n",
    "        },\n",
    "        \"outputId\": \"4376ad66-1a94-4cd6-bccc-02d894ac7b0e\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
